#!/usr/bin/env python3
import argparse, json, os, shutil, subprocess, sys, pathlib, datetime, re, tempfile, textwrap

ROOT = pathlib.Path(__file__).resolve().parent.parent

def get_version() -> str:
    try:
        vfile = ROOT / "VERSION"
        if vfile.exists():
            return vfile.read_text().strip()
    except Exception:
        pass
    try:
        res = subprocess.run(["git", "-C", str(ROOT), "describe", "--tags", "--always"], text=True, capture_output=True)
        if res.returncode == 0 and res.stdout.strip():
            return res.stdout.strip()
    except Exception:
        pass
    return "0.0.0+unknown"
# Always write artifacts under the current working directory
EXPORTS = pathlib.Path.cwd() / "exports"
MODULES = ROOT / "modules"
EXPORTS.mkdir(exist_ok=True)

def run(cmd, cwd=None, check=True):
    return subprocess.run(cmd, cwd=cwd, text=True, capture_output=True, check=check)

def write_json(path: pathlib.Path, data):
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(data, indent=2))

def validate_cmake_guidance(project_dir=None):
    """Validate CMakeLists.txt compliance with CMAKE_GUIDANCE.md patterns"""
    if project_dir is None:
        project_dir = pathlib.Path.cwd()
    else:
        project_dir = pathlib.Path(project_dir)

    cmake_file = project_dir / "CMakeLists.txt"

    result = {
        "cmake_file_exists": cmake_file.exists(),
        "compliance": {
            "compile_commands_export": False,
            "project_warnings_interface": False,
            "project_sanitizers_interface": False,
            "json_diagnostics": False,
            "cxx_standard_set": False,
            "lint_target": False
        },
        "suggestions": [],
        "overall_score": 0
    }

    if not cmake_file.exists():
        result["suggestions"].append("Create CMakeLists.txt with 'llmtk init'")
        return result

    try:
        cmake_content = cmake_file.read_text()

        # Check for required patterns from CMAKE_GUIDANCE.md
        patterns = {
            "compile_commands_export": "CMAKE_EXPORT_COMPILE_COMMANDS ON",
            "project_warnings_interface": "add_library(project_warnings INTERFACE)",
            "project_sanitizers_interface": "add_library(project_sanitizers INTERFACE)",
            "json_diagnostics": "fdiagnostics-format=json",
            "cxx_standard_set": "CMAKE_CXX_STANDARD",
            "lint_target": "add_custom_target(lint"
        }

        for key, pattern in patterns.items():
            if pattern in cmake_content:
                result["compliance"][key] = True
            else:
                # Add specific suggestions based on missing patterns
                if key == "compile_commands_export":
                    result["suggestions"].append("Add 'set(CMAKE_EXPORT_COMPILE_COMMANDS ON)' for clangd support")
                elif key == "project_warnings_interface":
                    result["suggestions"].append("Create project_warnings INTERFACE library for consistent warnings")
                elif key == "json_diagnostics":
                    result["suggestions"].append("Add JSON diagnostics support for LLM-friendly error output")
                elif key == "lint_target":
                    result["suggestions"].append("Add custom lint target for syntax-only checking")

        # Calculate overall compliance score
        compliant_count = sum(result["compliance"].values())
        total_checks = len(result["compliance"])
        result["overall_score"] = (compliant_count / total_checks) * 100

    except Exception as e:
        result["suggestions"].append(f"Error reading CMakeLists.txt: {e}")

    return result

def load_yaml(path: pathlib.Path):
    # Try PyYAML, then yq, else return None
    try:
        import yaml  # type: ignore
        with open(path, 'r') as f:
            return yaml.safe_load(f)
    except Exception:
        pass
    if shutil.which("yq"):
        try:
            conv = subprocess.run(["yq", "-o=json", str(path)], text=True, capture_output=True)
            if conv.returncode == 0 and conv.stdout:
                return json.loads(conv.stdout)
        except Exception:
            pass
    return None

def generate_reference_md(out_path: pathlib.Path):
    tools_manifest = ROOT/"manifest"/"tools.yaml"
    commands_manifest = ROOT/"manifest"/"commands.yaml"
    tools = load_yaml(tools_manifest)
    commands = load_yaml(commands_manifest)

    now = datetime.datetime.now(datetime.UTC).isoformat()
    lines = []
    lines.append("# Toolkit Reference")
    lines.append("")
    lines.append(f"Generated from manifests on {now}.")
    lines.append("")

    # Tools
    lines.append("## Tools")
    if tools and isinstance(tools, dict) and "tools" in tools:
        for name in sorted(tools["tools"].keys()):
            t = tools["tools"][name] or {}
            version = t.get("version")
            provides = t.get("provides") or []
            check = None
            if isinstance(t.get("check"), dict):
                check = " ".join(map(str, t["check"].get("cmd", [])))
            lines.append(f"- {name}")
            if version: lines.append(f"  - version: {version}")
            if provides: lines.append(f"  - provides: {', '.join(provides)}")
            if check: lines.append(f"  - check: `{check}`")
    else:
        # Fallback: embed raw YAML for visibility
        try:
            raw = tools_manifest.read_text()
            lines.append("````yaml")
            lines.append(raw.rstrip())
            lines.append("````")
        except Exception:
            lines.append("(tools manifest not found)")

    lines.append("")
    lines.append("## Commands")
    if commands and isinstance(commands, dict) and "commands" in commands:
        for name in sorted(commands["commands"].keys()):
            c = commands["commands"][name] or {}
            lines.append(f"- {name}")
            if c.get("description"): lines.append(f"  - description: {c['description']}")
            args = c.get("args") or []
            if args:
                arg_summaries = []
                for a in args:
                    if isinstance(a, dict):
                        nm = a.get("name")
                        req = a.get("required", False)
                        var = a.get("variadic", False)
                        frag = nm or "arg"
                        if req: frag += " (required)"
                        if var: frag += " (variadic)"
                        arg_summaries.append(frag)
                if arg_summaries:
                    lines.append(f"  - args: {', '.join(arg_summaries)}")
            runs = c.get("runs") or []
            if runs: lines.append(f"  - runs: {', '.join(runs)}")
            outs = c.get("outputs") or []
            if outs:
                for o in outs:
                    if isinstance(o, str):
                        lines.append(f"  - output: {o}")
                    elif isinstance(o, dict):
                        p = o.get("path") or o.get("file") or "(unknown)"
                        lines.append(f"  - output: {p}")
                        schema = o.get("schema")
                        if schema is not None:
                            try:
                                rendered = json.dumps(schema, indent=2)
                            except Exception:
                                rendered = str(schema)
                            lines.append("    schema:")
                            lines.append("    ```json")
                            for l in rendered.splitlines():
                                lines.append("    " + l)
                            lines.append("    ```")
            if c.get("json_summary"): lines.append(f"  - json_summary: {c['json_summary']}")
    else:
        try:
            raw = commands_manifest.read_text()
            lines.append("````yaml")
            lines.append(raw.rstrip())
            lines.append("````")
        except Exception:
            lines.append("(commands manifest not found)")

    out_path.parent.mkdir(parents=True, exist_ok=True)
    out_path.write_text("\n".join(lines) + "\n")



def generate_capabilities_json(out_path: pathlib.Path):
    """Emit a machine-readable capabilities summary for agents."""
    tools_manifest = ROOT/"manifest"/"tools.yaml"
    commands_manifest = ROOT/"manifest"/"commands.yaml"
    tools = load_yaml(tools_manifest) or {}
    commands = load_yaml(commands_manifest) or {}

    data = {
        "_meta": {
            "generated_at": datetime.datetime.now(datetime.UTC).isoformat(),
            "toolkit_version": get_version(),
            "tools_manifest": str(tools_manifest),
            "commands_manifest": str(commands_manifest),
        },
        "tools": {},
        "commands": {},
    }

    tools_section = tools.get("tools") if isinstance(tools, dict) else None
    if isinstance(tools_section, dict):
        for name, entry in tools_section.items():
            entry = entry or {}
            data["tools"][name] = {
                "version": entry.get("version"),
                "min_version": entry.get("min_version"),
                "provides": entry.get("provides") or [],
                "role": entry.get("role", "optional"),
                "install": entry.get("install") or {},
                "check": entry.get("check") or {},
                "fallbacks": entry.get("fallbacks") or [],
                "local_install": entry.get("local_install") or None,
            }

    commands_section = commands.get("commands") if isinstance(commands, dict) else None
    if isinstance(commands_section, dict):
        for name, entry in commands_section.items():
            entry = entry or {}
            data["commands"][name] = {
                "description": entry.get("description"),
                "args": entry.get("args") or [],
                "runs": entry.get("runs") or [],
                "outputs": entry.get("outputs") or [],
                "json_summary": entry.get("json_summary"),
                "examples": entry.get("examples") or [],
            }

    write_json(out_path, data)
    return out_path


def cmd_docs(_):
    out = ROOT/"docs"/"REFERENCE.md"
    generate_reference_md(out)
    print(str(out))

def cmd_capabilities(_):
    path = generate_capabilities_json(EXPORTS/"capabilities.json")
    print(str(path))

def adopt_existing_project(project_dir: pathlib.Path, project_name: str) -> int:
    """Generate an adoption report for an existing project without mutating sources."""
    print(f"🤝 Adopting existing project in {project_dir}")

    cmake_validation = validate_cmake_guidance(project_dir)
    compile_db = project_dir / "compile_commands.json"
    exported_compile_db = None
    compile_db_copy_error = None
    build_dir_candidates = []
    for candidate in ["build", "cmake-build-debug", "cmake-build-release"]:
        bdir = project_dir / candidate
        if bdir.exists() and bdir.is_dir():
            build_dir_candidates.append(str(bdir.resolve()))

    preset_names = [".clang-tidy", ".clang-format", "cmake-format.yaml", "pre-commit-config.yaml"]
    presets_status = []
    recommendations = list(cmake_validation.get("suggestions", []))
    for preset in preset_names:
        present = (project_dir / preset).exists()
        presets_status.append({"name": preset, "present": present})
        if not present:
            recommendations.append(f"Consider copying preset '{preset}' from llm-cpp-toolkit/presets")

    if not compile_db.exists():
        recommendations.append("Generate compile_commands.json via 'llmtk context export --build <build-dir>'")
    else:
        dest = EXPORTS / "compile_commands.json"
        try:
            dest.parent.mkdir(parents=True, exist_ok=True)
            if dest.exists() and dest.resolve() == compile_db.resolve():
                exported_compile_db = str(dest.resolve())
            else:
                shutil.copy2(compile_db, dest)
                exported_compile_db = str(dest.resolve())
        except Exception as exc:  # best effort copy
            compile_db_copy_error = str(exc)
            recommendations.append(
                "Copy existing compile_commands.json into exports/ (e.g. 'cp compile_commands.json exports/') for agents"
            )

    deduped_recs = []
    seen = set()
    for item in recommendations:
        if item and item not in seen:
            deduped_recs.append(item)
            seen.add(item)

    adoption_summary = {
        "mode": "existing",
        "project_name": project_name,
        "project_dir": str(project_dir.resolve()),
        "timestamp": datetime.datetime.now(datetime.UTC).isoformat(),
        "cmake_validation": cmake_validation,
        "artifacts": {
            "compile_commands": str(compile_db.resolve()) if compile_db.exists() else None,
            "build_directories": build_dir_candidates,
            "exports_compile_commands": exported_compile_db,
        },
        "presets": presets_status,
        "recommendations": deduped_recs,
    }

    out = EXPORTS / "init-existing.json"
    write_json(out, adoption_summary)
    capabilities_path = generate_capabilities_json(EXPORTS/"capabilities.json")

    print("📄 Adoption summary written to", out)
    print("📚 Capabilities manifest available at", capabilities_path)
    if exported_compile_db:
        print(f"📦 Copied existing compile_commands.json to {exported_compile_db}")
    elif compile_db_copy_error:
        print(f"⚠️ Failed to copy compile_commands.json: {compile_db_copy_error}")
    if cmake_validation["overall_score"] >= 80:
        print(f"✅ Existing CMake setup scores {cmake_validation['overall_score']:.0f}% against CMAKE_GUIDANCE.md")
    else:
        print(f"💡 CMake compliance is {cmake_validation['overall_score']:.0f}% – see recommendations above.")

    print("\n🚀 Suggested follow-ups:")
    for rec in deduped_recs[:5]:
        print(f"   • {rec}")
    if len(deduped_recs) > 5:
        print(f"   • ...and {len(deduped_recs) - 5} more (see adoption summary)")

    return 0


def cmd_init(args):
    """Initialize a new C++ project with CMAKE_GUIDANCE.md compliance"""
    project_name = args.name or pathlib.Path.cwd().name
    project_dir = pathlib.Path.cwd() if not args.name else pathlib.Path(args.name)

    # Create directory if it doesn't exist
    if args.name:
        if project_dir.exists():
            print(f"📂 Using existing project directory: {project_dir}")
        else:
            project_dir.mkdir(parents=True, exist_ok=True)
            print(f"📁 Created project directory: {project_dir}")

    # Check if CMakeLists.txt already exists
    cmake_file = project_dir / "CMakeLists.txt"
    if args.existing and not cmake_file.exists():
        print("❌ --existing specified but no CMakeLists.txt found in the target directory.")
        return 1

    if cmake_file.exists() and not args.force:
        return adopt_existing_project(project_dir, project_name)

    # Generate CMAKE_GUIDANCE.md compliant CMakeLists.txt with user options
    cmake_min_version = getattr(args, 'cmake_min', '3.28')
    cxx_standard = getattr(args, 'std', '23')
    enable_pic = getattr(args, 'pic', False)
    disable_sanitizers = getattr(args, 'no_sanitizers', False)
    preset = getattr(args, 'preset', 'full')

    # Handle sanitizers section based on user preference
    sanitizers_section = ""
    if not disable_sanitizers:
        sanitizers_section = '''
# 2) Sanitizers toggles (don't hardcode CMAKE_CXX_FLAGS_*; compose options instead)
option(ENABLE_ASAN "Enable AddressSanitizer" $<NOT:$<CXX_COMPILER_ID:MSVC>>)
option(ENABLE_UBSAN "Enable UBSan"           $<NOT:$<CXX_COMPILER_ID:MSVC>>)
add_library(project_sanitizers INTERFACE)
if (NOT MSVC)
  if (ENABLE_ASAN)
    target_compile_options(project_sanitizers INTERFACE -fsanitize=address)
    target_link_options(project_sanitizers    INTERFACE -fsanitize=address)
  endif()
  if (ENABLE_UBSAN)
    target_compile_options(project_sanitizers INTERFACE -fsanitize=undefined)
    target_link_options(project_sanitizers    INTERFACE -fsanitize=undefined)
  endif()
endif()'''
    else:
        sanitizers_section = '''
# 2) Sanitizers disabled per user preference
add_library(project_sanitizers INTERFACE)'''

    # Handle different presets for target and lint sections
    if preset == "minimal":
        target_section = f'''
# 3) Your target(s) - replace with your actual source files
add_executable({project_name} main.cpp)
target_link_libraries({project_name} PRIVATE project_warnings project_sanitizers)'''
        lint_section = ""
    elif preset == "library":
        target_section = f'''
# 3) Library target - adjust as needed
add_library({project_name} src/{project_name}.cpp)
target_include_directories({project_name} PUBLIC include)
target_link_libraries({project_name} PRIVATE project_warnings project_sanitizers)

# Optional: also build example executable
add_executable({project_name}_example examples/main.cpp)
target_link_libraries({project_name}_example PRIVATE {project_name} project_warnings project_sanitizers)'''
        lint_section = f'''
# 4) LLM-focused "lint" that compiles TUs with tight diagnostics (no linking)
get_target_property(LIB_SOURCES {project_name} SOURCES)
get_target_property(LIB_INCLUDES {project_name} INCLUDE_DIRECTORIES)
get_target_property(LIB_DEFS     {project_name} COMPILE_DEFINITIONS)
get_target_property(LIB_OPTS     {project_name} COMPILE_OPTIONS)

# Compose include and define flags portably
set(_lint_includes "")
if(LIB_INCLUDES)
  foreach(inc ${{LIB_INCLUDES}})
    list(APPEND _lint_includes -I${{inc}})
  endforeach()
endif()
set(_lint_defines "")
if(LIB_DEFS)
  foreach(def ${{LIB_DEFS}})
    list(APPEND _lint_defines -D${{def}})
  endforeach()
endif()

# Build a response file so the command stays short
set(_lint_rsp "${{CMAKE_BINARY_DIR}}/lint_args.rsp")
file(WRITE  "${{_lint_rsp}}" "")
if(LIB_OPTS)
  foreach(opt ${{LIB_OPTS}})
    file(APPEND "${{_lint_rsp}}" "${{opt}}\\n")
  endforeach()
endif()
foreach(def ${{_lint_defines}})
  file(APPEND "${{_lint_rsp}}" "${{def}}\\n")
endforeach()
foreach(inc ${{_lint_includes}})
  file(APPEND "${{_lint_rsp}}" "${{inc}}\\n")
endforeach()

# Pick flags per compiler
if (CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
  set(LINT_CORE_FLAGS
    -std=c++{cxx_standard} -fsyntax-only
    -Wfatal-errors -ferror-limit=1
    -ftemplate-backtrace-limit=6 -fconstexpr-backtrace-limit=3 -fmacro-backtrace-limit=2
    -fno-caret-diagnostics -fdiagnostics-color=never -fdiagnostics-show-option
    -fdiagnostics-format=json
  )
elseif (CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
  set(LINT_CORE_FLAGS
    -std=c++{cxx_standard} -fsyntax-only
    -Wfatal-errors -fmax-errors=1
    -fconcepts-diagnostics-depth=2
    -fno-diagnostics-show-caret -fdiagnostics-color=never
    -fdiagnostics-format=json
  )
else()
  # MSVC: fall back to /analyze JSON? For now: no-op lint with success.
  set(LINT_CORE_FLAGS "")
endif()

# One lint target that iterates all TU's; writes a single JSON per TU into build/lint/
add_custom_target(lint
  COMMENT "Running tight JSON diagnostics per translation unit..."
)
foreach(src ${{LIB_SOURCES}})
  get_filename_component(src_name "${{src}}" NAME_WE)
  set(out_json "${{CMAKE_BINARY_DIR}}/lint/${{src_name}}.json")
  file(MAKE_DIRECTORY "${{CMAKE_BINARY_DIR}}/lint")
  add_custom_command(TARGET lint POST_BUILD
    COMMAND ${{CMAKE_CXX_COMPILER}} "@${{_lint_rsp}}" ${{LINT_CORE_FLAGS}} "${{src}}" 2> "${{out_json}}"
    BYPRODUCTS "${{out_json}}"
    COMMENT "Lint ${{src_name}}"
    VERBATIM
  )
endforeach()'''
    else:  # preset == "full"
        target_section = f'''
# 3) Your target(s) - replace with your actual source files
add_executable({project_name} main.cpp)
target_link_libraries({project_name} PRIVATE project_warnings project_sanitizers)'''
        lint_section = f'''
# 4) LLM-focused "lint" that compiles TUs with tight diagnostics (no linking)
#    Important: use the *same* include dirs/defs/opts as {project_name} so headers resolve.
get_target_property(APP_SOURCES {project_name} SOURCES)
get_target_property(APP_INCLUDES {project_name} INCLUDE_DIRECTORIES)
get_target_property(APP_DEFS     {project_name} COMPILE_DEFINITIONS)
get_target_property(APP_OPTS     {project_name} COMPILE_OPTIONS)

# Compose include and define flags portably for non-MSVC compilers.
set(_lint_includes "")
if(APP_INCLUDES)
  foreach(inc ${{APP_INCLUDES}})
    list(APPEND _lint_includes -I${{inc}})
  endforeach()
endif()
set(_lint_defines "")
if(APP_DEFS)
  foreach(def ${{APP_DEFS}})
    list(APPEND _lint_defines -D${{def}})
  endforeach()
endif()

# Build a response file so the command stays short (token-cheap logs)
set(_lint_rsp "${{CMAKE_BINARY_DIR}}/lint_args.rsp")
file(WRITE  "${{_lint_rsp}}" "")
if(APP_OPTS)
  foreach(opt ${{APP_OPTS}})
    file(APPEND "${{_lint_rsp}}" "${{opt}}\\n")
  endforeach()
endif()
foreach(def ${{_lint_defines}})
  file(APPEND "${{_lint_rsp}}" "${{def}}\\n")
endforeach()
foreach(inc ${{_lint_includes}})
  file(APPEND "${{_lint_rsp}}" "${{inc}}\\n")
endforeach()

# Pick flags per compiler
if (CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
  set(LINT_CORE_FLAGS
    -std=c++{cxx_standard} -fsyntax-only
    -Wfatal-errors -ferror-limit=1
    -ftemplate-backtrace-limit=6 -fconstexpr-backtrace-limit=3 -fmacro-backtrace-limit=2
    -fno-caret-diagnostics -fdiagnostics-color=never -fdiagnostics-show-option
    -fdiagnostics-format=json
  )
elseif (CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
  set(LINT_CORE_FLAGS
    -std=c++{cxx_standard} -fsyntax-only
    -Wfatal-errors -fmax-errors=1
    -fconcepts-diagnostics-depth=2
    -fno-diagnostics-show-caret -fdiagnostics-color=never
    -fdiagnostics-format=json
  )
else()
  # MSVC: fall back to /analyze JSON? For now: no-op lint with success.
  set(LINT_CORE_FLAGS "")
endif()

# One lint target that iterates all TU's; writes a single JSON per TU into build/lint/
add_custom_target(lint
  COMMENT "Running tight JSON diagnostics per translation unit..."
)
foreach(src ${{APP_SOURCES}})
  get_filename_component(src_name "${{src}}" NAME_WE)
  set(out_json "${{CMAKE_BINARY_DIR}}/lint/${{src_name}}.json")
  file(MAKE_DIRECTORY "${{CMAKE_BINARY_DIR}}/lint")
  add_custom_command(TARGET lint POST_BUILD
    COMMAND ${{CMAKE_CXX_COMPILER}} "@${{_lint_rsp}}" ${{LINT_CORE_FLAGS}} "${{src}}" 2> "${{out_json}}"
    BYPRODUCTS "${{out_json}}"
    COMMENT "Lint ${{src_name}}"
    VERBATIM
  )
endforeach()'''

    # Handle Position Independent Code
    pic_section = ""
    if enable_pic:
        pic_section = "\n# Enable position independent code\nset(CMAKE_POSITION_INDEPENDENT_CODE ON)\n"

    cmake_template = f'''cmake_minimum_required(VERSION {cmake_min_version})
project({project_name} LANGUAGES CXX)

# Always declare the language level once
set(CMAKE_CXX_STANDARD {cxx_standard})
set(CMAKE_CXX_STANDARD_REQUIRED ON)
set(CMAKE_CXX_EXTENSIONS OFF){pic_section}

# Export compile_commands.json (handy for your reducer or tools)
set(CMAKE_EXPORT_COMPILE_COMMANDS ON)

# 1) Warnings-as-errors & friends — per-compiler, per-config, target-attachable
add_library(project_warnings INTERFACE)

if (MSVC)
  target_compile_options(project_warnings INTERFACE
    /W4 /WX /permissive- /Zc:preprocessor /Zc:__cplusplus /EHsc
    # optional noise trims:
    # /wd4244 /wd4267
  )
else()
  target_compile_options(project_warnings INTERFACE
    -Wall -Wextra -Wconversion -Wshadow -Werror
    -Wnon-virtual-dtor -Woverloaded-virtual -Wimplicit-fallthrough
    -fdiagnostics-show-option
  )
endif()

# 2) Sanitizers toggles (don't hardcode CMAKE_CXX_FLAGS_*; compose options instead)
option(ENABLE_ASAN "Enable AddressSanitizer" $<NOT:$<CXX_COMPILER_ID:MSVC>>)
option(ENABLE_UBSAN "Enable UBSan"           $<NOT:$<CXX_COMPILER_ID:MSVC>>)
add_library(project_sanitizers INTERFACE)
if (NOT MSVC)
  if (ENABLE_ASAN)
    target_compile_options(project_sanitizers INTERFACE -fsanitize=address)
    target_link_options(project_sanitizers    INTERFACE -fsanitize=address)
  endif()
  if (ENABLE_UBSAN)
    target_compile_options(project_sanitizers INTERFACE -fsanitize=undefined)
    target_link_options(project_sanitizers    INTERFACE -fsanitize=undefined)
  endif()
endif()

# 3) Your target(s) - replace with your actual source files
add_executable({project_name} main.cpp)
target_link_libraries({project_name} PRIVATE project_warnings project_sanitizers)

# 4) LLM-focused "lint" that compiles TUs with tight diagnostics (no linking)
#    Important: use the *same* include dirs/defs/opts as {project_name} so headers resolve.
get_target_property(APP_SOURCES {project_name} SOURCES)
get_target_property(APP_INCLUDES {project_name} INCLUDE_DIRECTORIES)
get_target_property(APP_DEFS     {project_name} COMPILE_DEFINITIONS)
get_target_property(APP_OPTS     {project_name} COMPILE_OPTIONS)

# Compose include and define flags portably for non-MSVC compilers.
set(_lint_includes "")
if(APP_INCLUDES)
  foreach(inc ${{APP_INCLUDES}})
    list(APPEND _lint_includes -I${{inc}})
  endforeach()
endif()

set(_lint_defines "")
if(APP_DEFS)
  foreach(def ${{APP_DEFS}})
    list(APPEND _lint_defines -D${{def}})
  endforeach()
endif()

# Build a response file so the command stays short (token-cheap logs)
set(_lint_rsp "${{CMAKE_BINARY_DIR}}/lint_args.rsp")
file(WRITE  "${{_lint_rsp}}" "")
if(APP_OPTS)
  foreach(opt ${{APP_OPTS}})
    file(APPEND "${{_lint_rsp}}" "${{opt}}\\n")
  endforeach()
endif()
foreach(def ${{_lint_defines}})
  file(APPEND "${{_lint_rsp}}" "${{def}}\\n")
endforeach()
foreach(inc ${{_lint_includes}})
  file(APPEND "${{_lint_rsp}}" "${{inc}}\\n")
endforeach()

# Pick flags per compiler
if (CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
  set(LINT_CORE_FLAGS
    -std=c++23 -fsyntax-only
    -Wfatal-errors -ferror-limit=1
    -ftemplate-backtrace-limit=6 -fconstexpr-backtrace-limit=3 -fmacro-backtrace-limit=2
    -fno-caret-diagnostics -fdiagnostics-color=never -fdiagnostics-show-option
    -fdiagnostics-format=json
  )
elseif (CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
  set(LINT_CORE_FLAGS
    -std=c++20 -fsyntax-only
    -Wfatal-errors -fmax-errors=1
    -fconcepts-diagnostics-depth=2
    -fno-diagnostics-show-caret -fdiagnostics-color=never
    -fdiagnostics-format=json
  )
else()
  # MSVC: fall back to /analyze JSON? For now: no-op lint with success.
  set(LINT_CORE_FLAGS "")
endif()

# One lint target that iterates all TU's; writes a single JSON per TU into build/lint/
add_custom_target(lint
  COMMENT "Running tight JSON diagnostics per translation unit..."
)
foreach(src ${{APP_SOURCES}})
  get_filename_component(src_name "${{src}}" NAME_WE)
  set(out_json "${{CMAKE_BINARY_DIR}}/lint/${{src_name}}.json")
  file(MAKE_DIRECTORY "${{CMAKE_BINARY_DIR}}/lint")
  add_custom_command(TARGET lint POST_BUILD
    COMMAND ${{CMAKE_CXX_COMPILER}} "@${{_lint_rsp}}" ${{LINT_CORE_FLAGS}} "${{src}}" 2> "${{out_json}}"
    BYPRODUCTS "${{out_json}}"
    COMMENT "Lint ${{src_name}}"
    VERBATIM
  )
endforeach()
'''

    # Write CMakeLists.txt
    cmake_file.write_text(cmake_template)
    print(f"✅ Created CMAKE_GUIDANCE.md compliant CMakeLists.txt")

    # Create main.cpp if it doesn't exist
    main_file = project_dir / "main.cpp"
    if not main_file.exists():
        main_template = f'''#include <iostream>

int main() {{
    std::cout << "Hello from {project_name}!\\n";
    return 0;
}}
'''
        main_file.write_text(main_template)
        print(f"✅ Created sample main.cpp")

    # Validate the created setup
    cmake_validation = validate_cmake_guidance(project_dir)
    print(f"🏗️ CMake compliance: ✅ {cmake_validation['overall_score']:.0f}% compliant with CMAKE_GUIDANCE.md")

    print(f"\n🚀 Next steps:")
    print(f"   • cd {project_dir if args.name else '.'}")
    print(f"   • llmtk context export    # Generate build context")
    print(f"   • cmake -B build -G Ninja  # Configure build")
    print(f"   • cmake --build build      # Build project")
    print(f"   • cmake --build build --target lint  # Run LLM-optimized linting")

    capabilities_path = generate_capabilities_json(EXPORTS/"capabilities.json")
    print(f"\n📚 Capabilities manifest available at {capabilities_path}")

    return 0

def cmd_doctor(args):
    # Load from manifest to get complete tool list
    tools_manifest = ROOT / "manifest" / "tools.yaml"
    if tools_manifest.exists():
        tools_config = load_yaml(tools_manifest)
        if tools_config and "tools" in tools_config:
            # Get all tools from manifest, prioritizing core and recommended
            all_tools = tools_config["tools"]
            tools = []
            for name, config in all_tools.items():
                role = config.get("role", "optional")
                if role in ["core", "recommended"]:
                    tools.append(name)
            # Add any remaining tools
            for name in all_tools.keys():
                if name not in tools:
                    tools.append(name)
        else:
            # Fallback list
            tools = [
                "cmake","ninja","clangd","clang-tidy","clang-format",
                "include-what-you-use","cppcheck","rg","fd","jq","yq","bear","ccache","mold"
            ]
    else:
        # Fallback list
        tools = [
            "cmake","ninja","clangd","clang-tidy","clang-format",
            "include-what-you-use","cppcheck","rg","fd","jq","yq","bear","ccache","mold"
        ]

    report = {"_meta": {"generated_at": datetime.datetime.now(datetime.UTC).isoformat()}}

    found_tools = []
    missing_core = []
    missing_recommended = []
    missing_optional = []

    # Add local bin to PATH for tool discovery (use same path as install command)
    local_bin = ROOT / ".llmtk" / "bin"
    old_path = os.environ.get("PATH", "")
    if local_bin.exists():
        os.environ["PATH"] = f"{local_bin}:{old_path}"

    for t in tools:
        # Get the actual command to check from the manifest
        actual_cmd = t
        if tools_manifest.exists() and tools_config and "tools" in tools_config:
            tool_config = tools_config["tools"].get(t, {})
            check_config = tool_config.get("check", {})
            if isinstance(check_config, dict) and "cmd" in check_config:
                actual_cmd = check_config["cmd"][0]  # First element is the command name

        path = shutil.which(actual_cmd)
        info = {"found": bool(path), "path": path or None}
        if path:
            try:
                out = run([actual_cmd, "--version"], check=False).stdout.splitlines()
                info["version_line"] = out[0] if out else None
            except Exception:
                info["version_line"] = None
            found_tools.append(t)
        else:
            # Categorize missing tools by role
            if tools_manifest.exists() and tools_config and "tools" in tools_config:
                tool_config = tools_config["tools"].get(t, {})
                role = tool_config.get("role", "optional")
                if role == "core":
                    missing_core.append(t)
                elif role == "recommended":
                    missing_recommended.append(t)
                else:
                    missing_optional.append(t)
            else:
                missing_core.append(t)  # Default to core for fallback
        report[t] = info

    # Restore original PATH
    os.environ["PATH"] = old_path

    # Add CMake validation to the report
    cmake_validation = validate_cmake_guidance()
    report["_cmake"] = cmake_validation

    # Add summary to report
    report["_summary"] = {
        "total_tools": len(tools),
        "found": len(found_tools),
        "missing": len(tools) - len(found_tools),
        "missing_core": missing_core,
        "missing_recommended": missing_recommended,
        "missing_optional": missing_optional,
        "cmake_compliance_score": cmake_validation["overall_score"]
    }

    out = EXPORTS / "doctor.json"
    write_json(out, report)

    # Print user-friendly summary if not being called from install
    if not hasattr(args, '_from_install'):
        # Check if this is CMake-focused or full health check
        cmake_only = hasattr(args, 'cmake') and args.cmake

        if cmake_only:
            print()
            print("🏗️ CMAKE COMPLIANCE CHECK")
            print("=" * 40)
        else:
            print()
            print("🏥 HEALTH CHECK SUMMARY")
            print("=" * 40)
            print(f"✅ Found: {len(found_tools)}/{len(tools)} tools")

        # Show different content based on mode
        if not cmake_only:
            if missing_core:
                print(f"\n❌ Missing core tools ({len(missing_core)}):")
                for tool in missing_core:
                    print(f"   • {tool}")

            if missing_recommended:
                print(f"\n⚠️ Missing recommended tools ({len(missing_recommended)}):")
                for tool in missing_recommended:
                    print(f"   • {tool}")

        # Show CMake compliance status (always shown)
        cmake_score = cmake_validation["overall_score"]
        if cmake_validation["cmake_file_exists"]:
            if cmake_score >= 80:
                print(f"\n🏗️ CMake setup: ✅ {cmake_score:.0f}% compliant with CMAKE_GUIDANCE.md")
            elif cmake_score >= 50:
                print(f"\n🏗️ CMake setup: ⚠️ {cmake_score:.0f}% compliant with CMAKE_GUIDANCE.md")
            else:
                print(f"\n🏗️ CMake setup: ❌ {cmake_score:.0f}% compliant with CMAKE_GUIDANCE.md")

            # Show detailed compliance breakdown in CMake-only mode
            if cmake_only:
                print(f"\n📋 Compliance Details:")
                for key, value in cmake_validation["compliance"].items():
                    status = "✅" if value else "❌"
                    readable_name = key.replace("_", " ").title()
                    print(f"   {status} {readable_name}")

            if cmake_validation["suggestions"]:
                suggestions_to_show = cmake_validation["suggestions"] if cmake_only else cmake_validation["suggestions"][:3]
                print("   CMake improvements needed:")
                for suggestion in suggestions_to_show:
                    print(f"   • {suggestion}")
        else:
            print(f"\n🏗️ CMake setup: ❌ No CMakeLists.txt found")
            print("   • Run 'llmtk init' to create LLM-optimized project structure")

        # Recommendations section
        needs_tools = missing_core or missing_recommended
        needs_cmake = cmake_score < 80

        if (not cmake_only and needs_tools) or needs_cmake:
            print(f"\n💡 RECOMMENDED ACTIONS:")
            if not cmake_only and needs_tools:
                print(f"   • Run 'llmtk install' to install missing tools")
                print(f"   • Use 'llmtk install --local' for non-sudo installation")
            if needs_cmake:
                print(f"   • Run 'llmtk init' to upgrade CMake setup for LLM workflows")
                print(f"   • See CMAKE_GUIDANCE.md for manual setup instructions")

        if not cmake_only:
            print(f"\n📄 Detailed report: {out}")

    print(str(out))

def cmd_context_export(args):
    # Check CMake compliance if requested
    if hasattr(args, 'require_cmake') and args.require_cmake:
        cmake_validation = validate_cmake_guidance()
        if not cmake_validation["cmake_file_exists"]:
            print("❌ Error: No CMakeLists.txt found. Use --require-cmake only in CMake projects.")
            print("💡 Run 'llmtk init' to create a compliant CMake project")
            return 1

        if cmake_validation["overall_score"] < 80:
            print(f"❌ Error: CMake compliance too low ({cmake_validation['overall_score']:.0f}% < 80%)")
            print("💡 Missing CMAKE_GUIDANCE.md patterns:")
            for suggestion in cmake_validation["suggestions"][:3]:
                print(f"   • {suggestion}")
            print("💡 Run 'llmtk init' to upgrade your CMake setup")
            return 1

        print(f"✅ CMake compliance verified ({cmake_validation['overall_score']:.0f}%)")

    build = pathlib.Path(args.build)
    build.mkdir(exist_ok=True)

    # Compile DB
    try:
        run(["cmake","-S",".","-B",str(build),"-G","Ninja","-DCMAKE_EXPORT_COMPILE_COMMANDS=ON"], check=True)
        if (build/"compile_commands.json").exists():
            (EXPORTS/"compile_commands.json").write_bytes((build/"compile_commands.json").read_bytes())
    except Exception as e:
        # If compile_commands missing, try bear as a fallback
        bear = shutil.which("bear")
        if bear:
            try:
                run([bear, "--", "cmake", "--build", str(build)], check=False)
                if (build/"compile_commands.json").exists():
                    (EXPORTS/"compile_commands.json").write_bytes((build/"compile_commands.json").read_bytes())
            except Exception:
                pass
    # If still missing but project root has a compile_commands.json, copy it
    if not (EXPORTS/"compile_commands.json").exists() and (pathlib.Path.cwd()/"compile_commands.json").exists():
        (EXPORTS/"compile_commands.json").write_bytes((pathlib.Path.cwd()/"compile_commands.json").read_bytes())

    # CMake File API codemodel
    q = build/".cmake"/"api"/"v1"/"query"; q.mkdir(parents=True, exist_ok=True)
    (q/"codemodel-v2").write_text("")
    run(["cmake","--build",str(build)], check=False)
    reply = build/".cmake"/"api"/"v1"/"reply"
    if reply.exists():
        (EXPORTS/"cmake-file-api").mkdir(exist_ok=True)
        for p in reply.iterdir():
            (EXPORTS/"cmake-file-api"/p.name).write_bytes(p.read_bytes())

    summary = {
        "compile_commands": "exports/compile_commands.json" if (EXPORTS/"compile_commands.json").exists() else None,
        "cmake_file_api": {
            "dir": "exports/cmake-file-api/",
            "files": sorted([p.name for p in (EXPORTS/"cmake-file-api").iterdir()]) if (EXPORTS/"cmake-file-api").exists() else []
        } if (EXPORTS/"cmake-file-api").exists() else None,
        "generated_at": datetime.datetime.now(datetime.UTC).isoformat()
    }
    write_json(EXPORTS/"context.json", summary)
    print(str(EXPORTS/"context.json"))

def cmd_analyze(args):
    reports = EXPORTS/"reports"; reports.mkdir(exist_ok=True)
    compile_db = EXPORTS/"compile_commands.json"
    paths = args.paths or []

    def read_compile_db_files():
        files = []
        if compile_db.exists():
            try:
                data = json.loads(compile_db.read_text())
                files = [entry.get("file") for entry in data if entry.get("file")]
            except Exception:
                files = []
        # Filter by user-provided paths if any
        if paths:
            keep = []
            for f in files:
                for p in paths:
                    if pathlib.Path(f).is_absolute():
                        if str(f).startswith(str(pathlib.Path(p).resolve())) or str(f).find("/"+p+"/") != -1:
                            keep.append(f); break
                    else:
                        if str(f).startswith(p):
                            keep.append(f); break
            files = keep
        # Dedup while preserving order
        seen = set(); uniq = []
        for f in files:
            if f not in seen:
                seen.add(f); uniq.append(f)
        return uniq

    files_in_db = read_compile_db_files()

    def run_proc(cmd, cwd=None):
        return subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)

    # clang-tidy with export-fixes
    clang_tidy_path = shutil.which("clang-tidy")
    clang_tidy_report = {"available": bool(clang_tidy_path), "diagnostics": [], "fixes": [], "version": None, "inputs": []}
    if clang_tidy_path:
        try:
            v = run_proc([clang_tidy_path, "--version"]).stdout.splitlines()
            clang_tidy_report["version"] = v[0] if v else None
        except Exception:
            pass
        # Choose files to analyze
        target_files = files_in_db
        clang_tidy_report["inputs"] = target_files[:50]  # cap in report
        tidy_diags = []
        tidy_fixes = []
        diag_re = re.compile(r"^(?P<file>[^:]+):(?P<line>\d+):(?!\d+:)\s*(?P<col>\d+): (?P<severity>warning|error|note): (?P<msg>.*?)(?: \[(?P<check>[A-Za-z0-9_.\-]+)\])?$")
        # If no compile DB, still try on explicit paths
        if not target_files and paths:
            # restrict to common C/C++ extensions
            exts = (".c", ".cc", ".cxx", ".cpp", ".h", ".hh", ".hpp", ".hxx")
            for p in paths:
                pp = pathlib.Path(p)
                if pp.is_file() and pp.suffix in exts:
                    target_files.append(str(pp))
                elif pp.is_dir():
                    for f in pp.rglob("*"):
                        if f.suffix in exts:
                            target_files.append(str(f))
        # Analyze (best-effort, sequential to keep simple)
        for f in target_files[:200]:  # prevent runaway
            fixes_yaml = pathlib.Path(tempfile.gettempdir())/f"llmtk_tidy_{abs(hash(f))}.yaml"
            if fixes_yaml.exists():
                try: fixes_yaml.unlink()
                except Exception: pass
            cmd = [clang_tidy_path, f, "-quiet", f"-export-fixes={fixes_yaml}"]
            if compile_db.exists():
                # clang-tidy accepts directory or file to -p; pass dir containing the DB
                cmd.extend(["-p", str(compile_db.parent.resolve())])
            res = run_proc(cmd)
            for line in (res.stdout + "\n" + res.stderr).splitlines():
                m = diag_re.match(line.strip())
                if m:
                    d = m.groupdict()
                    d["line"] = int(d["line"]); d["col"] = int(d["col"])
                    tidy_diags.append(d)
            # Parse export-fixes YAML (if any)
            if fixes_yaml.exists():
                content = load_yaml(fixes_yaml)
                if content and isinstance(content, dict):
                    # content has Diagnostics: [{DiagnosticMessage:{Message,FilePath,FileOffset}, Replacements:[{FilePath,Offset,Length,ReplacementText}]}]
                    diags = content.get("Diagnostics") or []
                    for item in diags:
                        dm = item.get("DiagnosticMessage") or {}
                        repl = item.get("Replacements") or []
                        tidy_fixes.append({
                            "file": dm.get("FilePath"),
                            "message": dm.get("Message"),
                            "file_offset": dm.get("FileOffset"),
                            "replacements": [
                                {
                                    "file": r.get("FilePath"),
                                    "offset": r.get("Offset"),
                                    "length": r.get("Length"),
                                    "replacement": r.get("ReplacementText"),
                                } for r in repl if isinstance(r, dict)
                            ],
                        })
                try: fixes_yaml.unlink()
                except Exception: pass
        clang_tidy_report["diagnostics"] = tidy_diags
        clang_tidy_report["fixes"] = tidy_fixes
    write_json(reports/"clang-tidy.json", clang_tidy_report)

    # include-what-you-use (IWYU)
    iwyu_bin = shutil.which("include-what-you-use")
    iwyu_tool = shutil.which("iwyu-tool")
    iwyu_report = {"available": bool(iwyu_bin or iwyu_tool), "version": None, "suggestions": []}
    if iwyu_bin or iwyu_tool:
        # Try to get version line
        try:
            if iwyu_bin:
                vv = run_proc([iwyu_bin, "--version"]).stdout.splitlines()
                iwyu_report["version"] = vv[0] if vv else None
        except Exception:
            pass
        out = None
        if iwyu_tool and compile_db.exists():
            # Run across the compilation database
            res = run_proc([iwyu_tool, "-p", str(compile_db.parent.resolve())])
            out = res.stdout or res.stderr
        elif iwyu_bin and files_in_db:
            # Try first few files using compile DB path; IWYU will discover flags via -Xiwyu?
            # We fallback to plain invocation which may be noisy
            collected = []
            for f in files_in_db[:20]:
                res = run_proc([iwyu_bin, f])
                collected.append((res.stdout or "") + "\n" + (res.stderr or ""))
            out = "\n".join(collected)
        def parse_iwyu(text: str):
            suggestions = {}
            current = None
            mode = None  # 'add' or 'remove'
            for raw in text.splitlines():
                line = raw.strip()
                if not line:
                    mode = None
                    continue
                m_add = re.search(r"^(.*) should add these lines:", line)
                m_rem = re.search(r"^(.*) should remove these lines:", line)
                if m_add or m_rem:
                    current = (m_add or m_rem).group(1).strip()
                    entry = suggestions.setdefault(current, {"add": [], "remove": []})
                    mode = 'add' if m_add else 'remove'
                    continue
                if line.startswith("The full include-list for "):
                    current = None
                    mode = None
                    continue
                if mode in ('add','remove') and (line.startswith('#include') or line.startswith('namespace') or line.startswith('using')):
                    # IWYU annotates with comments; keep the include text as-is
                    suggestions.setdefault(current, {"add": [], "remove": []})[mode].append(line)
            return [{"file": f, **v} for f, v in suggestions.items()]
        if out:
            iwyu_report["suggestions"] = parse_iwyu(out)[:200]
    write_json(reports/"iwyu.json", iwyu_report)

    # cppcheck
    cppcheck_bin = shutil.which("cppcheck")
    cppcheck_report = {"available": bool(cppcheck_bin), "version": None, "diagnostics": []}
    if cppcheck_bin:
        try:
            vv = run_proc([cppcheck_bin, "--version"]).stdout.splitlines()
            cppcheck_report["version"] = vv[0] if vv else None
        except Exception:
            pass
        xml_tmp = pathlib.Path(tempfile.gettempdir())/"llmtk_cppcheck.xml"
        cmd = [cppcheck_bin, "--enable=all", "--inconclusive", "--quiet", "--xml", "--xml-version=2"]
        if compile_db.exists():
            cmd.extend(["--project", str(compile_db)])
        else:
            # Fall back to paths list or current dir
            search_paths = paths or ["."]
            cmd.extend(search_paths)
        res = subprocess.run(cmd, text=True, capture_output=True)
        # cppcheck writes XML to stderr
        xml_data = res.stderr
        diags = []
        try:
            import xml.etree.ElementTree as ET
            root = ET.fromstring(xml_data)
            for error in root.iterfind('.//errors/error'):
                ed = error.attrib
                locs = []
                for loc in error.iterfind('location'):
                    locs.append({
                        "file": loc.attrib.get("file"),
                        "line": int(loc.attrib.get("line", "0")),
                        "column": int(loc.attrib.get("column", "0"))
                    })
                diags.append({
                    "id": ed.get("id"),
                    "severity": ed.get("severity"),
                    "msg": ed.get("msg"),
                    "verbose": ed.get("verbose"),
                    "locations": locs
                })
        except Exception:
            # If XML parsing fails, include raw for inspection
            diags = [{"raw": xml_data[:200000]}]
        cppcheck_report["diagnostics"] = diags
    write_json(reports/"cppcheck.json", cppcheck_report)

    print(str(reports))

def cmd_reduce(args):
    repros = EXPORTS/"repros"; repros.mkdir(exist_ok=True)
    cvise = shutil.which("cvise")
    report = {"input": args.input, "test_cmd": args.test_cmd, "cvise_available": bool(cvise)}
    if not cvise:
        report["note"] = "cvise not found; skip"
        write_json(repros/"report.json", report)
        print(str(repros/"report.json"))
        return
    # Minimal shell-out; users can expand
    try:
        run([cvise, args.input, "--", "bash", "-lc", args.test_cmd], check=False)
        report["note"] = "cvise run attempted"
    except Exception as e:
        report["error"] = str(e)
    write_json(repros/"report.json", report)
    print(str(repros/"report.json"))

def detect_package_manager():
    """Detect available package manager"""
    managers = [
        ("apt", ["apt-get", "apt"]),
        ("dnf", ["dnf"]),
        ("pacman", ["pacman"]),
        ("brew", ["brew"]),
        ("nix", ["nix-env"])
    ]

    for name, commands in managers:
        for cmd in commands:
            if shutil.which(cmd):
                return name
    return None

def install_tool_with_package_manager(tool_name, tool_config, pm):
    """Install a tool using system package manager"""
    if "install" not in tool_config or pm not in tool_config["install"]:
        return False

    packages = tool_config["install"][pm]
    if not packages:
        return False

    print(f"  📦 Installing {tool_name} via {pm}...")

    # Build install command based on package manager
    if pm == "apt":
        cmd = ["sudo", "apt-get", "update", "&&", "sudo", "apt-get", "install", "-y"] + packages
    elif pm == "dnf":
        cmd = ["sudo", "dnf", "install", "-y"] + packages
    elif pm == "pacman":
        cmd = ["sudo", "pacman", "-S", "--noconfirm"] + packages
    elif pm == "brew":
        cmd = ["brew", "install"] + packages
    elif pm == "nix":
        cmd = ["nix-env", "-iA"] + [f"nixpkgs.{pkg}" for pkg in packages]
    else:
        return False

    try:
        if pm == "apt":
            # Handle apt's compound command - suppress normal output but show errors
            update_result = subprocess.run(["sudo", "apt-get", "update"],
                                         text=True, capture_output=True)
            if update_result.returncode != 0:
                # Only show if it's a real error, not just GPG warnings
                if "E:" in update_result.stderr and "NO_PUBKEY" not in update_result.stderr:
                    print(f"    ⚠️ apt-get update warning (continuing): {update_result.stderr.strip()}")

            result = subprocess.run(["sudo", "apt-get", "install", "-y"] + packages,
                                  check=True, text=True, capture_output=True)
        elif pm in ["dnf", "pacman"]:
            result = subprocess.run(cmd, check=True, text=True, capture_output=True)
        else:
            result = subprocess.run(cmd, check=True, text=True, capture_output=True)

        print(f"    ✅ {tool_name} installed successfully")
        return True
    except subprocess.CalledProcessError as e:
        print(f"    ❌ Failed to install {tool_name}")

        # Show specific error for debugging
        if e.stderr and e.stderr.strip():
            # Extract key error messages, skip verbose output
            error_lines = [line.strip() for line in e.stderr.split('\n')
                          if line.strip() and ('E:' in line or 'Error:' in line or 'unable to locate' in line.lower())]
            if error_lines:
                print(f"       Error: {error_lines[0]}")

        return False

def install_tool_locally(tool_name, tool_config, local_bin):
    """Install a tool locally"""
    if "local_install" not in tool_config:
        print(f"    ❌ No local install method for {tool_name}")
        return False

    print(f"  🔧 Installing {tool_name} locally...")
    local_config = tool_config["local_install"]

    if "github_repo" in local_config:
        success = install_from_github(tool_name, tool_config, local_bin)
        if success:
            print(f"    ✅ {tool_name} installed locally")
        else:
            print(f"    ❌ Failed to install {tool_name} locally")
        return success

    return False

def install_tool_basic(tool_name, local_bin):
    """Basic fallback installation for specific tools"""
    if tool_name == "cppcheck":
        script = MODULES / "simple-install.sh"
        if script.exists():
            result = run([str(script)], check=False)
            return result.returncode == 0
    elif tool_name == "include-what-you-use":
        script = MODULES / "simple-install.sh"
        if script.exists():
            result = run([str(script)], check=False)
            return result.returncode == 0

    print(f"No basic installation method available for {tool_name}")
    return False

def install_from_github(tool_name, config, local_bin):
    """Install tool from GitHub releases using manifest configuration"""
    local_config = config.get("local_install", {})
    repo = local_config.get("github_repo")

    if not repo:
        print(f"No GitHub repo specified for {tool_name}")
        return False

    print(f"Installing {tool_name} locally from {repo}")

    # Use the enhanced local installer with manifest data
    enhanced_installer = MODULES / "enhanced-install.sh"
    if enhanced_installer.exists():
        # Pass manifest data as environment variables
        env = os.environ.copy()
        env.update({
            "LLMTK_TOOL_NAME": tool_name,
            "LLMTK_GITHUB_REPO": repo,
            "LLMTK_RELEASE_PATTERN": local_config.get("release_pattern", ""),
            "LLMTK_BINARY_PATH": local_config.get("binary_path", ""),
            "LLMTK_BUILD_METHOD": local_config.get("build_method", ""),
            "LLMTK_LOCAL_BIN": str(local_bin),
            "LLMTK_MANIFEST_DATA": json.dumps(local_config)
        })

        # Add checksums as JSON
        if "checksums" in local_config:
            env["LLMTK_CHECKSUMS"] = json.dumps(local_config["checksums"])

        # Add version tag if specified
        if "version_tag" in local_config:
            env["LLMTK_VERSION_TAG"] = local_config["version_tag"]

        result = subprocess.run([str(enhanced_installer), tool_name], env=env, text=True, capture_output=True)

        # Show stderr output for user feedback
        if result.stderr:
            for line in result.stderr.strip().split('\n'):
                if line.strip():
                    print(line)

        return result.returncode == 0

    # Fallback to basic installation if enhanced installer not available
    print(f"Enhanced installer not found, using basic method for {tool_name}")
    return install_tool_basic(tool_name, local_bin)

def cmd_install(args):
    """Install missing tools using manifest-driven approach"""
    tools_manifest = ROOT / "manifest" / "tools.yaml"
    if not tools_manifest.exists():
        print(f"Error: Tools manifest not found at {tools_manifest}", file=sys.stderr)
        return 1

    # Load tools manifest
    tools_config = load_yaml(tools_manifest)
    if not tools_config or "tools" not in tools_config:
        print("Error: Invalid tools manifest", file=sys.stderr)
        return 1

    # Determine installation method
    use_local = getattr(args, 'local', False)
    pm = None if use_local else detect_package_manager()

    if not use_local and not pm:
        print("No package manager detected, falling back to local installation")
        use_local = True

    # Prepare local bin directory
    local_bin = ROOT / ".llmtk" / "bin"
    local_bin.mkdir(parents=True, exist_ok=True)

    # Install missing tools
    tools_to_install = []
    if hasattr(args, 'tools') and args.tools:
        tools_to_install = args.tools
    else:
        # Install all core and recommended tools that are missing
        for tool_name, tool_config in tools_config["tools"].items():
            if tool_config.get("role") in ["core", "recommended"]:
                if not shutil.which(tool_name):
                    tools_to_install.append(tool_name)

    if not tools_to_install:
        print("All tools are already installed")
        cmd_doctor(None)
        return 0

    print(f"🚀 Installing {len(tools_to_install)} missing tools...")
    print(f"   Method: {'local' if use_local else f'package manager ({pm})'}")
    print()

    installed = []
    failed = []
    skipped = []

    for tool_name in tools_to_install:
        if tool_name not in tools_config["tools"]:
            print(f"⚠️ {tool_name} not found in manifest, skipping")
            skipped.append(tool_name)
            continue

        tool_config = tools_config["tools"][tool_name]

        if use_local:
            if install_tool_locally(tool_name, tool_config, local_bin):
                installed.append(tool_name)
            else:
                # Fall back to simple installer for specific tools
                if tool_name in ["cppcheck", "include-what-you-use"]:
                    script = MODULES / "simple-install.sh"
                    if script.exists():
                        print(f"  🔄 Using fallback installer for {tool_name}")
                        result = run([str(script)], check=False)
                        if result.returncode == 0:
                            installed.append(tool_name)
                        else:
                            failed.append(tool_name)
                    else:
                        failed.append(tool_name)
                else:
                    failed.append(tool_name)
        else:
            if install_tool_with_package_manager(tool_name, tool_config, pm):
                installed.append(tool_name)
            else:
                print(f"  🔄 Falling back to local install for {tool_name}")
                if install_tool_locally(tool_name, tool_config, local_bin):
                    installed.append(tool_name)
                else:
                    failed.append(tool_name)

    # Update PATH for doctor check
    if local_bin.exists():
        old_path = os.environ.get("PATH", "")
        os.environ["PATH"] = f"{local_bin}:{old_path}"

    # Print comprehensive summary
    print()
    print("=" * 60)
    print("📊 INSTALLATION SUMMARY")
    print("=" * 60)

    if installed:
        print(f"✅ Successfully installed ({len(installed)}):")
        for tool in installed:
            print(f"   • {tool}")

    if failed:
        print(f"\n❌ Failed to install ({len(failed)}):")
        for tool in failed:
            print(f"   • {tool}")

    if skipped:
        print(f"\n⚠️ Skipped ({len(skipped)}):")
        for tool in skipped:
            print(f"   • {tool}")

    print(f"\n📈 Total: {len(installed)}/{len(tools_to_install)} tools successfully installed")

    # Generate updated doctor report
    print("\n🔍 Running health check...")
    # Create a dummy args object to signal we're being called from install
    class DummyArgs:
        _from_install = True
    cmd_doctor(DummyArgs())

    # Show next steps
    if failed:
        print("\n🛠️ NEXT STEPS:")
        print("   • Run 'llmtk install --local' to try local installation")
        print("   • Check 'llmtk doctor' output for specific issues")
        print("   • Install failed tools manually")

    if use_local or any(local_bin.glob("*")):
        print(f"\n📁 Local tools directory: {local_bin}")
        print(f"   Add to your shell: export PATH=\"{local_bin}:$PATH\"")

    return 0 if installed else 1

def main():
    ap = argparse.ArgumentParser(prog="llmtk", description="LLM-friendly C++/CMake toolkit")
    ap.add_argument("--version", action="version", version=f"llmtk {get_version()}")
    sub = ap.add_subparsers(dest="cmd", required=True)
    doctor_parser = sub.add_parser("doctor", help="Check tool availability and CMake compliance")
    doctor_parser.add_argument("--cmake", action="store_true", help="Focus on CMake compliance only")
    doctor_parser.set_defaults(fn=cmd_doctor)

    cx = sub.add_parser("context", help="context commands").add_subparsers(dest="sub", required=True)
    cx_exp = cx.add_parser("export", help="Export build context for LLMs")
    cx_exp.add_argument("--build", default="build", help="Build directory path")
    cx_exp.add_argument("--require-cmake", action="store_true", help="Require CMAKE_GUIDANCE.md compliance")
    cx_exp.set_defaults(fn=cmd_context_export)

    an = sub.add_parser("analyze"); an.add_argument("paths", nargs="*"); an.set_defaults(fn=cmd_analyze)

    rd = sub.add_parser("reduce"); rd.add_argument("input"); rd.add_argument("test_cmd"); rd.set_defaults(fn=cmd_reduce)

    sub.add_parser("docs").set_defaults(fn=cmd_docs)
    sub.add_parser("capabilities").set_defaults(fn=cmd_capabilities)

    init_parser = sub.add_parser("init", help="Initialize LLM-optimized C++ project")
    init_parser.add_argument("name", nargs="?", help="Project name (uses current directory if not specified)")
    init_parser.add_argument("--force", action="store_true", help="Overwrite existing CMakeLists.txt")
    init_parser.add_argument("--existing", action="store_true", help="Adopt an existing project without overwriting CMake files")

    # Customization options
    init_parser.add_argument("--std", choices=["17", "20", "23", "26"], default="23", help="C++ standard version")
    init_parser.add_argument("--cmake-min", default="3.28", help="Minimum CMake version required")
    init_parser.add_argument("--pic", action="store_true", help="Enable position independent code by default")
    init_parser.add_argument("--no-sanitizers", action="store_true", help="Disable sanitizer options")
    init_parser.add_argument("--preset", choices=["minimal", "full", "library"], default="full", help="Project template preset")

    init_parser.set_defaults(fn=cmd_init)

    install_parser = sub.add_parser("install", help="Install missing tools")
    install_parser.add_argument("--local", action="store_true", help="Force local installation (no sudo)")
    install_parser.add_argument("tools", nargs="*", help="Specific tools to install")
    install_parser.set_defaults(fn=cmd_install)

    args = ap.parse_args()
    # map nested subcommand
    if getattr(args, "sub", None):
        return args.fn(args)
    return args.fn(args)

if __name__ == "__main__":
    sys.exit(main())
